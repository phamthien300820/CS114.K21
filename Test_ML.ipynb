{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Test ML.ipynb",
      "provenance": [],
      "mount_file_id": "1n7VTi4p8zj0bYyjd5KQC5uOwjIjeYTyz",
      "authorship_tag": "ABX9TyOgRERTvtaYU14VlNApLhTp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phamthien300820/CS114.K21/blob/master/Test_ML.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ur3ySzGZ3HZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "44ce79cb-4e60-4870-921d-9edaf4687888"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7noRtNhaAkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Khai báo các thư viện cần thiết\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab.patches import cv2_imshow\n",
        "import os\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akx6_QytbgR5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%tensorflow_version 1.x"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRQqhPOeST1u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 568
        },
        "outputId": "1574bdd2-1b41-466a-81cd-e87b05849f5e"
      },
      "source": [
        "\n",
        "!pip3 install scipy\n",
        "!pip3 install numpy\n",
        "!pip3 install scipy\n",
        "!pip3 install opencv-python\n",
        "!pip3 install pillow\n",
        "!pip3 install matplotlib\n",
        "!pip3 install h5py\n",
        "!pip3 install keras\n",
        "!pip install https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.1/imageai-2.0.1-py3-none-any.whl"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (1.18.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scipy) (1.18.5)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.18.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (7.0.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.18.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from cycler>=0.10->matplotlib) (1.12.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.10.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.18.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.12.0)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.3.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.10.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.12.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.18.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.8)\n",
            "Collecting imageai==2.0.1\n",
            "\u001b[?25l  Downloading https://github.com/OlafenwaMoses/ImageAI/releases/download/2.0.1/imageai-2.0.1-py3-none-any.whl (137kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 809kB/s \n",
            "\u001b[?25hInstalling collected packages: imageai\n",
            "Successfully installed imageai-2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQUHgtd-ZabT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "74d5baf8-07ce-4063-ff10-66aa38b2b378"
      },
      "source": [
        "!cd drive\n",
        "execution_path = os.getcwd()\n",
        "execution_path"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vIEbRYebTYZs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177
        },
        "outputId": "38a24cb3-a525-4abb-e64b-337548c8d515"
      },
      "source": [
        "from imageai.Detection import ObjectDetection\n",
        "import os\n",
        "\n",
        "execution_path = \"/content/drive/My Drive/Colab Notebooks\"\n",
        "\n",
        "detector = ObjectDetection()\n",
        "detector.setModelTypeAsRetinaNet()\n",
        "detector.setModelPath( os.path.join(execution_path , \"resnet50_coco_best_v2.0.1.h5\"))\n",
        "detector.loadModel()\n",
        "\n",
        "execution_path =\"/content/drive/My Drive/Train/Have\"\n",
        "custom_objects = detector.CustomObjects(car=True, motorcycle=True)\n",
        "detections = detector.detectCustomObjectsFromImage(custom_objects=custom_objects, input_image=os.path.join(execution_path,\"IMG_20200620_074214.jpg\"), output_image_path=os.path.join(execution_path,\"IMG_20200620_074214_1.jpg\"), minimum_percentage_probability=30)\n",
        "\n",
        "for eachObject in detections:\n",
        "    print(eachObject[\"name\"] , \" : \", eachObject[\"percentage_probability\"])\n",
        "    print(\"--------------------------------\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tracking <tf.Variable 'Variable_20:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_21:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_22:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_23:0' shape=(9, 4) dtype=float32> anchors\n",
            "tracking <tf.Variable 'Variable_24:0' shape=(9, 4) dtype=float32> anchors\n",
            "motorcycle  :  32.39491581916809\n",
            "--------------------------------\n",
            "motorcycle  :  46.950483322143555\n",
            "--------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PzcBFOn9nJfP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# import the necessary packages\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import AveragePooling2D\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from imutils import paths\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import os\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dplUF1KnUlV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "f01db16b-f40d-4f3c-e0d1-d635827d1464"
      },
      "source": [
        "import cv2,os\n",
        "\n",
        "data_path='/content/drive/My Drive/Train'\n",
        "categories=os.listdir(data_path)\n",
        "labels=[i for i in range(len(categories))]\n",
        "\n",
        "label_dict=dict(zip(categories,labels)) #empty dictionary\n",
        "\n",
        "print(label_dict)\n",
        "print(categories)\n",
        "print(labels)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'Have': 0, 'Not': 1}\n",
            "['Have', 'Not']\n",
            "[0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNFTruYGn16H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "data=[]\n",
        "target=[]\n",
        "\n",
        "\n",
        "for category in categories:\n",
        "    folder_path=os.path.join(data_path,category)\n",
        "    img_names=os.listdir(folder_path)\n",
        "        \n",
        "    for img_name in img_names:\n",
        "        img_path=os.path.join(folder_path,img_name)\n",
        "        img=cv2.imread(img_path)\n",
        "\n",
        "        try:\n",
        "            gray=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)           \n",
        "            #Coverting the image into gray scale\n",
        "            resized=cv2.resize(gray,(224,224))\n",
        "            image = preprocess_input(resized)\n",
        "            #resizing the gray scale into 50x50, since we need a fixed common size for all the images in the dataset\n",
        "            data.append(image)\n",
        "            target.append(label_dict[category])\n",
        "            #appending the image and the label(categorized) into the list (dataset)\n",
        "           \n",
        "\n",
        "        except Exception as e:\n",
        "            print('Exception:',e)\n",
        "            #if any exception rasied, the exception will be printed here. And pass to the next image"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fz92JsNfoaOR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "data=np.array(data)\n",
        "data=np.reshape(data,(data.shape[0],224,224,1))\n",
        "target=np.array(target)\n",
        "\n",
        "from keras.utils import np_utils\n",
        "\n",
        "new_target=np_utils.to_categorical(target)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrkGaw7gocgW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data,test_data,train_target,test_target=train_test_split(data,new_target,test_size=0.2,random_state=42)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmVslwYQofIa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "aug = ImageDataGenerator(\n",
        "\trotation_range=20,\n",
        "\tzoom_range=0.15,\n",
        "\twidth_shift_range=0.2,\n",
        "\theight_shift_range=0.2,\n",
        "\tshear_range=0.15,\n",
        "\thorizontal_flip=True,\n",
        "\tfill_mode=\"nearest\")"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZFLa2aio8TX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation,Flatten,Dropout\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "model=Sequential()\n",
        "\n",
        "model.add(Conv2D(200,(3,3),input_shape=data.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The first CNN layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Conv2D(100,(3,3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#The second convolution layer followed by Relu and MaxPooling layers\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dropout(0.5))\n",
        "#Flatten layer to stack the output convolutions from second convolution layer\n",
        "model.add(Dense(50,activation='relu'))\n",
        "#Dense layer of 64 neurons\n",
        "model.add(Dense(2,activation='softmax'))\n",
        "#The Final layer with two outputs for two categories\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNvJYUUfpCf9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "26281ccd-f182-49cf-eb4b-8e209b7eb22b"
      },
      "source": [
        "print(\"[INFO] training head...\")\n",
        "checkpoint = ModelCheckpoint('model-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')\n",
        "H = model.fit(\n",
        "\taug.flow(train_data, train_target, batch_size=2),\n",
        "\tsteps_per_epoch=len(train_data) // 2,\n",
        "\tvalidation_data=(test_data, test_target),\n",
        "\tvalidation_steps=len(test_data) // 2,\n",
        "\tepochs=3,callbacks=[checkpoint])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training head...\n",
            "Epoch 1/3\n",
            "5/5 [==============================] - 8s 2s/step - loss: 4.0323 - accuracy: 0.8000 - val_loss: 1.5895e-07 - val_accuracy: 1.0000\n",
            "Epoch 2/3\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3873 - accuracy: 0.9000 - val_loss: 0.1396 - val_accuracy: 1.0000\n",
            "Epoch 3/3\n",
            "5/5 [==============================] - 6s 1s/step - loss: 0.3688 - accuracy: 0.9000 - val_loss: 0.1488 - val_accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwYxx1CYpeJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predIdxs = model.predict(test_data, batch_size=2)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSSlKbYXpf0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predIdxs = np.argmax(predIdxs)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6V_qvrGipj2s",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 640
        },
        "outputId": "e0458379-9ffa-432b-ad15-3ac14cf2b34d"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, 20), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"accuracy\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, 20), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-40-4772261a4538>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstyle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ggplot\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"val_loss\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mH\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"accuracy\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"train_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (20,) and (3,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}