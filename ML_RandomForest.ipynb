{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RandomForest.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPvZasiS7VKpDPlesCjtVc7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/phamthien300820/CS114.K21/blob/master/ML_RandomForest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cppSi694HWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "e1efc424-be3d-411c-82e6-f42f0668b62a"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5LJMvwooixB2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "20f2fc6f-458d-43af-97da-09e39d3b32ef"
      },
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "!pip install mahotas\n",
        "import mahotas\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting mahotas\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/1f/01d805bc3588da8343373c279702d0fca4dc55f631873d9f2e159f9287ac/mahotas-1.4.10-cp36-cp36m-manylinux2010_x86_64.whl (5.7MB)\n",
            "\u001b[K     |████████████████████████████████| 5.7MB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from mahotas) (1.18.5)\n",
            "Installing collected packages: mahotas\n",
            "Successfully installed mahotas-1.4.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1trlgUicDeQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Đường dẫn output\n",
        "output_path = \"/content/drive/My Drive/X_i1\"\n",
        "\n",
        "# Đường dẫn dữ liệu training\n",
        "train_path = \"/content/drive/My Drive/Machine_Learning Helmet\"\n",
        "\n",
        "# lấy nhẵn training\n",
        "train_labels = os.listdir(train_path)\n",
        "train_labels.sort()\n",
        "\n",
        "# Kích thước khi ảnh resize\n",
        "fixed_size = tuple((100, 100))\n",
        "\n",
        "bins = 8\n",
        "\n",
        "# danh sách trống để giữ các feature vectors và nhãn \n",
        "global_features = []\n",
        "labels = []"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOZjtUrAKngQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fd_hu_moments(image):\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    feature = cv2.HuMoments(cv2.moments(image)).flatten()\n",
        "    return feature"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--L9JctYKohr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fd_haralick(image):\n",
        "    #chuyển về ảnh gray\n",
        "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    haralick = mahotas.features.haralick(gray).mean(axis=0)\n",
        "    return haralick"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HurMwHNFKoqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def fd_histogram(image, mask=None):\n",
        "    #chuyển đổi hình ảnh sang màu HSV\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
        "    hist  = cv2.calcHist([image], [0, 1, 2], None, [bins, bins, bins], [0, 256, 0, 256, 0, 256])\n",
        "    cv2.normalize(hist, hist)\n",
        "    return hist.flatten()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a_wOCoVexJO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d0127ff7-dd5d-498c-95c5-31cfe75f1c41"
      },
      "source": [
        "train_labels"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Có người đi xe máy', 'Không có xe máy']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsjZ3SmncKS0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "01d7a171-9b9d-424a-8d24-2d4977a97dd0"
      },
      "source": [
        "for training_name in train_labels:\n",
        "    \n",
        "    dir = os.path.join(train_path, training_name)\n",
        "    # nhãn đang được train hiện tại\n",
        "    current_label = training_name\n",
        "    # Duyệt tất cả các ảnh trong mỗi tập con\n",
        "    for image in tqdm(os.listdir(dir)):\n",
        "        \n",
        "        try:\n",
        "          path = os.path.join(dir,image)\n",
        "          #Đọc ảnh và resize lại theo fixed_size\n",
        "          image = cv2.imread(path)\n",
        "          image = cv2.resize(image, fixed_size)\n",
        "\n",
        "          \n",
        "          fv_hu_moments = fd_hu_moments(image)\n",
        "          fv_haralick   = fd_haralick(image)\n",
        "          fv_histogram  = fd_histogram(image)\n",
        "\n",
        "          \n",
        "          global_feature = np.hstack([fv_histogram, fv_hu_moments, fv_haralick])\n",
        "\n",
        "          # cập nhật danh sách các nhãn và feature vectors\n",
        "          labels.append(current_label)\n",
        "          global_features.append(global_feature)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    print(\"[STATUS] processed folder: {}\".format(current_label))\n",
        "\n",
        "print(\"[STATUS] completed Global Feature Extraction...\")\n",
        "\n",
        "le = LabelEncoder()\n",
        "target = le.fit_transform(labels)\n",
        "\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "rescaled_features = scaler.fit_transform(global_features)\n",
        "\n",
        "# lưu feature vector bằng HDF5\n",
        "h5f_data = h5py.File(output_path+'data.h5', 'w')\n",
        "h5f_data.create_dataset('dataset_1', data=np.array(rescaled_features))\n",
        "\n",
        "h5f_label = h5py.File(output_path+'labels.h5', 'w')\n",
        "h5f_label.create_dataset('dataset_1', data=np.array(target))\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "print(\"[STATUS] end of training..\")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1226/1226 [13:48<00:00,  1.48it/s]\n",
            "  0%|          | 0/1221 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[STATUS] processed folder: Có người đi xe máy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1221/1221 [13:31<00:00,  1.50it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[STATUS] processed folder: Không có xe máy\n",
            "[STATUS] completed Global Feature Extraction...\n",
            "[STATUS] end of training..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuwqNyhvvwrP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "610d5af4-cbc0-4878-fae4-7605584bebc3"
      },
      "source": [
        "output_path = \"\\content\\X\"\n",
        "\n",
        "# Số lượng cây ở RandomForest\n",
        "num_trees = 300\n",
        "\n",
        "bins = 8\n",
        "\n",
        "# số hình ảnh mỗi lớp\n",
        "images_per_class = 10;\n",
        "\n",
        "# nhập vector đặc trưng và nhãn được training\n",
        "h5f_data = h5py.File('/content/drive/My Drive/X_i1data.h5', 'r')\n",
        "h5f_label = h5py.File('/content/drive/My Drive/X_i1labels.h5', 'r')\n",
        "\n",
        "global_features_string = h5f_data['dataset_1']\n",
        "global_labels_string = h5f_label['dataset_1']\n",
        "\n",
        "global_features = np.array(global_features_string)\n",
        "global_labels = np.array(global_labels_string)\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "\n",
        "#  Tạo model - Random Forests\n",
        "clf  = RandomForestClassifier(n_estimators=num_trees)\n",
        "clf.fit(global_features, global_labels)\n",
        "\n",
        "# Đường dẫn đến dữ liệu test\n",
        "test_path = \"/content/drive/My Drive/Train_1\"\n",
        "# lấy labels của test\n",
        "test_labels = os.listdir(test_path)\n",
        "\n",
        "\n",
        "test_labels.sort()\n",
        "print(test_labels)\n",
        "\n",
        "test_features = []\n",
        "test_results = []\n",
        "for testing_name in test_labels:\n",
        "    dir = os.path.join(test_path, testing_name)\n",
        "    current_label = testing_name\n",
        "    for image in tqdm(os.listdir(dir)):\n",
        "        try:\n",
        "          path = os.path.join(dir,image)\n",
        "          # đọc hình ảnh và resize của nó với fixed-size\n",
        "          image = cv2.imread(path)\n",
        "          image = cv2.resize(image, fixed_size)\n",
        "\n",
        "\n",
        "          fv_hu_moments = fd_hu_moments(image)\n",
        "          fv_haralick   = fd_haralick(image)\n",
        "          fv_histogram  = fd_histogram(image)\n",
        "\n",
        "          test_results.append(current_label)\n",
        "          test_features.append(np.hstack([fv_histogram, fv_hu_moments, fv_haralick]))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Dự đoán nhãn của ảnh thử nghiệm\n",
        "le = LabelEncoder()\n",
        "y_result = le.fit_transform(test_results)\n",
        "y_pred = clf.predict(test_features)\n",
        "\n",
        "print(y_pred)\n",
        "print(\"Kết quả: \", (y_pred == y_result).tolist().count(True)/len(y_result))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "  0%|          | 0/182 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['.ipynb_checkpoints', 'Có người đi xe máy', 'Không có xe máy']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 182/182 [00:28<00:00,  6.38it/s]\n",
            "100%|██████████| 163/163 [00:26<00:00,  6.12it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 1 0]\n",
            "Kết quả:  0.4681647940074906\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTSJpVAP5DRD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c1809105-b891-42cd-e3ee-f41d6f717ba1"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_result, y_pred, labels=[0, 1]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.48      0.16      0.24       140\n",
            "           1       0.47      0.80      0.59       127\n",
            "\n",
            "    accuracy                           0.47       267\n",
            "   macro avg       0.47      0.48      0.42       267\n",
            "weighted avg       0.47      0.47      0.41       267\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FnIq5P_FVhQP",
        "colab_type": "text"
      },
      "source": [
        "Lưu model và test lại:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MfFQVT6cPJ5L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "classifier_file = \"model1.h5\"\n",
        "with open(classifier_file, 'wb') as outfile:\n",
        "                pickle.dump((clf), outfile)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4GgeGePT9Yw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2,os\n",
        "loaded_model = pickle.load(open('/content/drive/My Drive/RDC.h5', 'rb'))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fu-qJtbfU6t_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "b12657a4-cf4b-4e30-fa16-01085d9dc3b3"
      },
      "source": [
        "h5f_data = h5py.File('/content/drive/My Drive/X_i1data.h5', 'r')\n",
        "h5f_label = h5py.File('/content/drive/My Drive/X_i1labels.h5', 'r')\n",
        "\n",
        "global_features_string = h5f_data['dataset_1']\n",
        "global_labels_string = h5f_label['dataset_1']\n",
        "\n",
        "global_features = np.array(global_features_string)\n",
        "global_labels = np.array(global_labels_string)\n",
        "\n",
        "h5f_data.close()\n",
        "h5f_label.close()\n",
        "\n",
        "# Đường dẫn đến dữ liệu test\n",
        "test_path = \"/content/drive/My Drive/Train_1\"\n",
        "# lấy labels của test\n",
        "test_labels = os.listdir(test_path)\n",
        "\n",
        "\n",
        "test_labels.sort()\n",
        "print(test_labels)\n",
        "\n",
        "test_features = []\n",
        "test_results = []\n",
        "for testing_name in test_labels:\n",
        "    dir = os.path.join(test_path, testing_name)\n",
        "    current_label = testing_name\n",
        "    for image in tqdm(os.listdir(dir)):\n",
        "        try:\n",
        "          path = os.path.join(dir,image)\n",
        "          # đọc hình ảnh và resize của nó với fixed-size\n",
        "          image = cv2.imread(path)\n",
        "          image = cv2.resize(image, fixed_size)\n",
        "\n",
        "\n",
        "          fv_hu_moments = fd_hu_moments(image)\n",
        "          fv_haralick   = fd_haralick(image)\n",
        "          fv_histogram  = fd_histogram(image)\n",
        "\n",
        "          test_results.append(current_label)\n",
        "          test_features.append(np.hstack([fv_histogram, fv_hu_moments, fv_haralick]))\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "# Dự đoán nhãn của ảnh thử nghiệm\n",
        "le = LabelEncoder()\n",
        "y_result = le.fit_transform(test_results)\n",
        "y_pred = loaded_model.predict(test_features)\n",
        "\n",
        "print(y_pred)\n",
        "print(\"Kết quả: \", (y_pred == y_result).tolist().count(True)/len(y_result))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0it [00:00, ?it/s]\n",
            "  0%|          | 0/182 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "['.ipynb_checkpoints', 'Có người đi xe máy', 'Không có xe máy']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 182/182 [00:27<00:00,  6.53it/s]\n",
            "100%|██████████| 163/163 [00:26<00:00,  6.20it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 0 0 0 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1 0 0 1 1\n",
            " 1 1 1 1 1 1 1 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 0\n",
            " 1 1 1 1 1 0 1 0]\n",
            "Kết quả:  0.4681647940074906\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}